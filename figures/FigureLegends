## Figure Legends
Figure 1. A) The gold standard, laboratory-based workflow for measuring the knee adduction moment (KAM). After motion capture data is collected and semi-manually pre-processed, it is combined with force plate data to compute the KAM using inverse dynamics. B) The workflow for the current study. We use the coordinates of 13 anatomical landmarks from motion capture (to simulate video keypoints) as inputs into a neural network trained to predict the peak KAM. C) Our proposed future workflow for the automated measurement of the KAM. After collecting 2D video of gait, keypoints (e.g., joint positions) could be detected automatically using OpenPose25. A neural network would predict the peak KAM using these keypoints as input.

Figure 2. The predicted peak knee adduction moment (KAM) from the neural network (NN) using 3D anatomical landmark positions as input (3D neural network) vs. the peak KAM calculated from inverse dynamics (ID) plotted against the y=x line. Presented data are for test subjects from the baseline and foot progression angle modification trials. Each point represents a single step, and a single color represents the steps from both legs of a subject.

Figure 3. The top five most salient features (features that, when changed, have the greatest effect on the predicted peak KAM) normalized by the most salient feature for the 3D, frontal plane, and sagittal plane neural networks (left). The positions and Cartesian coordinate directions of the most salient features (right) where x corresponds to the anterior-posterior direction, y to medio-lateral, and z to superior-inferior. 

Figure 4. The peak knee adduction moment (KAM) estimated by the 3D neural network (NN) and inverse dynamics (ID) from the baseline (natural walking) trial. Data are averaged over all baseline steps for each leg of each subject (represented by a color) in the test set plotted against the y=x line. 

Figure 5. The average change in the peak knee adduction moment (KAM) estimated by the 3D neural network (NN) vs. inverse dynamics (ID) for 5°, 10°, and 15° foot progression angle modifications for each leg of each subject in the test set. The accuracy (acc.) of classification is increases with increasing degrees of foot progression angle modification.

Figure 6. The performance of neural networks that use planar projections of anatomical landmark positions as inputs. A) The frontal plane neural network predicts the peak KAM with similar accuracy to the 3D neural network (r2=0.85). B) The sagittal plane neural network is less accurate (r2=0.14) than the 3D or frontal plane neural networks. Presented data are for test subjects from the baseline and foot progression angle modification trials. A point represents a single step, and a single color represents the steps from both legs of a subject.
